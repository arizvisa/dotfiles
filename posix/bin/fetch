#!/usr/bin/env bash
url=$1
destination=$2

## options
CURL=`type -P curl.sh || type -P curl`
CURL_PARAMS=(-L -s -S)
CURL_OPTIONS=(-k '--keepalive-time 10' '--retry 65535' '--retry-delay 1' '--retry-max-time 0' --anyauth)

OPENSSL=`type -P openssl.sh || type -P openssl`

# wtf, curl. why are these only available in libcurl?
[ -z "$CURLOPT_COOKIE" ] ||     CURL_PARAMS=("${CURL_PARAMS[@]}" "-b $CURLOPT_COOKIE")
[ -z "$CURLOPT_COOKIEFILE" ] || CURL_PARAMS=("${CURL_PARAMS[@]}" "-b $CURLOPT_COOKIEFILE")
[ -z "$CURLOPT_COOKIEJAR" ] ||  CURL_PARAMS=("${CURL_PARAMS[@]}" "-c $CURLOPT_COOKIEJAR")

## curl(1) related utilities
curl_support()
{
    "$CURL" "${CURL_PARAMS[@]}" $1 2>&1 | grep -q URL
}

curl_head()
{
    ec=0

    # First try making a HEAD request with the --head parameter.
    CURL_HEAD_PARAMS=(--head --no-show-error)
    "$CURL" "${CURL_PARAMS[@]}" "${CURL_ARGS[@]}" "${CURL_HEAD_PARAMS[@]}" "$@"

    ec=$?
    if [ "$ec" -eq 0 ]; then
        return $ec
    fi

    # Otherwise make a regular GET request, but clamping the file size and
    # writing the response headers to stdout.
    CURL_HEAD_PARAMS=(--no-show-error --max-filesize 1 --output /dev/null --dump-header - )
    "$CURL" "${CURL_PARAMS[@]}" "${CURL_ARGS[@]}" "${CURL_HEAD_PARAMS[@]}" "$@"

    # On success, we should get the "maximum file size exceeded" error (63).
    ec=$?
    if [ "$ec" -eq 63 ]; then
        return 0
    fi

    return $ec
}

curl_get()
{
    "$CURL" "${CURL_PARAMS[@]}" "${CURL_ARGS[@]}" "$@"
}

curl_resume()
{
    "$CURL" "${CURL_PARAMS[@]}" "${CURL_ARGS[@]}" -C- "$@"
}

CURL_ARGS=()
for opt in "${CURL_OPTIONS[@]}"; do
    if curl_support "$opt"; then
        CURL_ARGS=("${CURL_ARGS[@]}" $opt)
    fi
done

## openssl(1) related utilities
openssl_digest_types()
{
    "$OPENSSL" dgst -list | grep '^-' | paste -sd' ' - | tr -s ' ' | xargs printf "%s\0"
}

openssl_digest_file()
{
    path="$1" && shift
    "$OPENSSL" dgst "$@" -binary -- "$path" | od -A none -tx1 | paste -sd' ' - | tr -d ' '
}

openssl_digest_everything()
{
    path="$1" && shift
    if [ ! -e "$path" ]; then
        printf "Unable to locate the requested filename (%s)\n" "$path" 1>&2
        return 1
    fi

    openssl_digest_types | while read -d $'\0' option; do
        IFS=- read _ algorithm <<< "$option"
        (printf "%s\n" "$algorithm" && openssl_digest_file "$path" "$option") | xargs printf "%s:%s\n"
    done
}

openssl_digest_sorted()
{
    openssl_digest_everything "$@" | while IFS=$'\n' read line; do
        count=`wc -c <<< "$line"`
        printf "%s\t%s\n" "$count" "$line"
    done | sort -r -t $'\t' -n -k 1 | cut -d $'\t' -f2
}

## utilities for determining the expected and actual size
httpsize()
{
    url=$1
    curl_head -- "$url" | grep -ie "^Content-Length: *" | head -n 1 | tr " \n\t\r" ' ' | sed 's/^[Cc]ontent-[Ll]ength: *//;s/ *$//' | xargs printf '%d\n'
}

filesize()
{
    filename=$1
    case "$platform" in
    *bsd*|darwin*)
        stat -f '%z' "$filename"
        ;;
    msys|cygwin|linux*)
        stat -c '%s' "$filename"
        ;;
    *)
        exit 1
    esac
}

## utilities for performing the actual transfer and updating the user
calculatepercent()
{
    numerator=$1
    denominator=$2
    scale=$3
    printf "scale=%d; %d / %d * 100.\n" "${scale:-3}" "$numerator" "$denominator" | bc
}

transferstatus()
{
    filename=$1
    expected=$2

    size=0
    while [ "$size" -lt "$expected" ]; do
        size=`filesize "$filename"`
        percentage=`calculatepercent "$size" "$expected"`
        printf "%s %0.3f%% %d/%d\n" "$filename" "$percentage" "$size" "$expected" 1>&2
        sleep 1
        echo -ne "\r\x1b[1A\x1b[K" 1>&2
    done
    printf "%s %0.3f%% %d/%d\n" "$filename" "$percentage" "$size" "$expected" 1>&2
}

filestatus()
{
    filename=$1

    size=0
    while true; do
        size=`filesize "$filename"`
        printf "%s %d\n" "$filename" "$size" 1>&2
        sleep 1
        echo -ne "\r\x1b[1A\x1b[K" 1>&2
    done
    printf "%s %d\n" "$filename" "$size" 1>&2
}

## entrypoints that will be used to perform the user's requested action
download()
{
    url=$1
    target=$2

    # first get the expected size and the current file size.
    expected=`httpsize "$url"`
    touch "$target" || return $?
    size=`filesize "$target"`

    # check if we were untable to determine the expected
    # size, and monitor the size of the file until done.
    if [ -z "$expected" ]; then
        filestatus "$target" &
        killthis=$!

    # if the file size is smaller than the expected size,
    # then just monitor its status to update our progress.
    elif [ "$size" -lt "$expected" ]; then
        transferstatus "$target" "$expected" &
        killthis=$!

    elif [ "$size" -lt "$expected" ]; then
        transferstatus "$target" "$expected" &
        killthis=$!

    # if the file size is too large, then we need to
    # complain about the mismatched sizes.
    elif [ "$size" -gt "$expected" ]; then
        printf "%s: Output file at \"%s\" has already been fetched (%d), but is larger than (%d > %d) the expected size (%d).\n" "$0" "$target" "$size" "$size" "$expected" "$expected" 1>&2
        return 27 # EFBIG

    # if the file size is the same, then we don't need
    # to do anything else.
    else
        printf "%s: Output file at \"%s\" has already been fetched (%d) and is of the expected size (%d == %d).\n" "$0" "$target" "$size" "$size" "$expected" 1>&2
        return 0
    fi

    #"curl.exe" -# -C- -k --retry 999 --retry-delay 0 --retry-max-time 0 --compressed -o "$target" -O "$url" 1>&2 &
    curl_resume -o "$target" -- "$url" 1>&2 &
    pid=$!

    wait -p pid $pid
    ec=$?

    size=`filesize "$target"`
    while [ ! -z "$expected" ] && [ "$size" -lt "$expected" ] && [ "$ec" -eq 18 -o "$ec" -eq 26 -o "$ec" -eq 28 -o "$ec" -eq 52 -o "$ec" -eq 55 -o "$ec" -eq 56 ]; do
        printf "%s: Ignoring error code %d, retrying transfer at offset %d of file \"%s\".\n" "$0" "$ec" "$size" "$target" 1>&2
        curl_resume -o "$target" -- "$url" 1>&2 &
        wait -p pid $!
        ec=$?
        size=`filesize "$target"`
    done

    [ -z "$killthis" ] || kill "$killthis" 2>/dev/null

    [ "$ec" -gt 0 ] && printf '%s: Error code %d was returned by downloader.\n' "$0" "$ec" 1>&2
    return $ec
}

abort()
{
    url=$1
    target=$2
    trap - INT
    printf "%s: Abort!\n" "$0" 1>&2

    printf "%s: Aborted download of \"%s\" to \"%s\"\n" "$0" "$url" "$target" 1>&2
    openssl_digest_sorted "$target"
    exit 4
}

## actual logic for the script
guessed=`basename "$url"`
if [ -z "$destination" ]; then
    filename="$guessed"
elif [ -d "$destination" ]; then
    IFS= read -d $'\0' filename < <( printf '%s/%s' "$destination" "$guessed" )
else
    filename="$destination"
fi

# sanity check that we support the platform
size=`filesize /dev/null`
if [ -z "$size" ] || [ "$size" -ne 0 ]; then
    printf "%s: Current platform (%s) is unsupported platform.\n" "$0" "$platform" 1>&2
    exit 1
fi

# if the filename exists and we can write to it, then let the user know that we're resuming
if [ -f "$filename" ] && [ -w "$filename" ]; then
    resume=`filesize "$filename"`
    printf "%s: Resuming transfer at offset %d of file \"%s\" with url \"%s\".\n" "$0" "$resume" "$filename" "$url" 2>&2

# if the filename exists, then its either not a file or writable
elif [ -e "$filename" ]; then
    IFS= read -d $'\0' message < <( [ -w "$filename" ] && printf 'a file' || printf 'writable' )
    printf "%s: Destination at \"%s\" currently exists and is not %s.\n" "$0" "$filename" "$message" 1>&2
    printf "%s: Aborting download from url \"%s\".\n" "$0" "$url" 1>&2
    exit 17 # EEXIST

# otherwise, we just let the user know we're downloading the file
else
    printf "%s: Downloading file from url \"%s\" to \"%s\".\n" "$0" "$url" "$filename" 1>&2
fi

# check if we need to create the target directory
rp=`cygpath -u "$filename"`
rd=`dirname "$rp"`
wd=`cygpath -u "."`
td="${rd##$wd/}"
if [ "$rd" != "$wd" ]; then
    printf "%s: Creating target directory \"%s\".\n" "$0" "$rd" 1>&2
    mkdir -p "$rd"
fi

# allow the user to abort. after aborting, calculate all of the digests
# for the file that we downloaded, sort them, and display them tohe caller
trap "abort \"\$url\" \"\$filename\"" INT
download "$url" "$filename"
ec=$?
if [ $ec -gt 0 ]; then
    printf "%s: Aborting download from url \"%s\" due to error %d.\n" "$0" "$url" "$ec" 1>&2
    [ -e "$rp" ] && [ ! -s "$rp" ] && printf "%s: Found zero-sized file from partial download at \"%s\".\n" "$0" "$filename" 1>&2 && rm -v "$rp"
    [ "$rd" != "$wd" ] && printf "%s: Removing created target directory \"%s\".\n" "$0" "$rd" 1>&2 && rmdir -p "$td" 2>/dev/null
    [ "$rd" != "$wd" ] && [ -d "$rd" ] && printf "%s: Unable to remove target directory \"%s\".\n" "$0" "$rd" 1>&2
    exit $ec
else
    printf "%s: Completed download from url \"%s\".\n" "$0" "$url" 1>&2
fi

# we downloaded the file and only need to calculate all the available
# digests before we properly exit
openssl_digest_sorted "$filename"
exit "$ec"
